{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Volumes/FAIR/DC-Image-Analysis/DC-project-master/cleancode')\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import plotly \n",
    "plotly.offline.init_notebook_mode()\n",
    "import findeyes\n",
    "import nibabel as nib\n",
    "import core\n",
    "import SimpleITK as sitk\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.morphology import binary_erosion as be\n",
    "from scipy.ndimage.morphology import binary_fill_holes as bfh\n",
    "from scipy.ndimage.morphology import binary_dilation as bd\n",
    "from scipy.ndimage.morphology import binary_opening as bo\n",
    "from scipy.ndimage.morphology import binary_closing as bc\n",
    "from scipy.ndimage.morphology import grey_dilation as gd\n",
    "from skimage import measure\n",
    "from skimage.morphology import remove_small_objects as rso\n",
    "\n",
    "ForamenInfo = []\n",
    "paths = ['/Volumes/FAIR/Sinead/DC-Project-Images/original/Sample3/S3_Pre-op.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/Sample4/S4_Pre-op.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/Sample5/S5_Pre_rigid.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/SampleB/SB_Pre-op.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/SampleC/SC_Pre-op.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/SampleD/SD_Pre-op.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/SampleF/SF_Pre-op.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/SampleG/SG_Pre-op.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/SampleH/SH_Pre-op.nrrd',\n",
    "         '/Volumes/FAIR/Sinead/DC-Project-Images/original/SampleI/SI_Pre-op.nrrd',\n",
    "         '/Users/fair00542/Desktop/TestImages/ScanB/1.3.12.2.1107.5.1.4.51967.30000014110308064564000003663.dcm',\n",
    "         '/Users/fair00542/Desktop/TestImages/ScanD/1.3.12.2.1107.5.1.4.95198.30000015040208110913600035430.dcm',\n",
    "         '/Users/fair00542/Desktop/TestImages/ScanE/1.3.12.2.1107.5.1.4.95198.30000015061008243097400047439.dcm',\n",
    "         '/Users/fair00542/Desktop/TestImages/ScanF/1.3.12.2.1107.5.1.4.95198.30000015051507521609300034666.dcm',\n",
    "         '/Users/fair00542/Desktop/TestImages/ScanG/1.3.12.2.1107.5.1.4.95198.30000015072708211605400036464.dcm',\n",
    "         '/Users/fair00542/Desktop/TestImages/ScanH/1.2.840.113619.2.55.3.2634693835.766.1437720278.192.2.dcm',\n",
    "         '/Users/fair00542/Desktop/TestImages/ScanI/1.3.12.2.1107.5.1.4.95198.30000015071109310409300075668.dcm',\n",
    "         '/Users/fair00542/Desktop/TestImages/ScanJ/1.2.392.200036.9116.2.6.1.48.1221600807.1432222275.897467.dcm']\n",
    "\n",
    "for pathnumber in range(len(paths)):\n",
    "# for pathnumber in range(1):\n",
    "    path = paths[pathnumber]\n",
    "    print 'iteration number', pathnumber\n",
    "    if path.endswith('.nii') or path.endswith('.nii.gz'):\n",
    "        array, ConstPixelSpacing, affine = core.nifti2np(path)\n",
    "    #     bone = core.thresholdnp(array, 1100, 1500)\n",
    "    #     softtissue  = core.thresholdnp(array, 0, 80)\n",
    "        # visual     = core.thresholdnp(self.scan.array, -100, 1500)\n",
    "\n",
    "    elif path.endswith('.dcm'):\n",
    "        array, ConstPixelSpacing, origin, path, affine = core.dicom2np(path)\n",
    "        maskPath = os.path.join(os.path.split(os.path.dirname(path))[0], 'level2.nii.gz')\n",
    "        skullPath = os.path.join(os.path.dirname(path), 'opt_skull_contour.nii.gz')\n",
    "    #     bone = core.thresholdnp(array, 900, 1500)\n",
    "        softtissue  = core.thresholdnp(array, 0, 80)\n",
    "\n",
    "    elif path.endswith('.nrrd'):\n",
    "        array, ConstPixelSpacing, affine = core.nrrd2np(path)\n",
    "        array=np.swapaxes(array, 0, 1)\n",
    "    #     bone = core.thresholdnp(array, 1100, 1500)\n",
    "        softtissue  = core.thresholdnp(array, 0, 80)\n",
    "        maskPath = os.path.join(os.path.dirname(path), 'level2.nii.gz')\n",
    "        skullPath = os.path.join(os.path.dirname(path), 'opt_skull_contour.nii.gz')\n",
    "\n",
    "    level2 = nib.load(maskPath)\n",
    "    mask2 = level2.get_data()\n",
    "    skull = nib.load(skullPath)\n",
    "    skull_contour = skull.get_data()\n",
    "    skullcontourReshaped = core.reshape(skull_contour, ConstPixelSpacing)\n",
    "    mask2Reshaped = core.reshape(mask2, ConstPixelSpacing)\n",
    "\n",
    "    # Take out saggital slices with masks \n",
    "    ValidSlices = np.nonzero(mask2)[0]\n",
    "    # Find the slice with deepest mask point in z direction\n",
    "    DeepestSag = []\n",
    "    for i in range(ValidSlices[0],ValidSlices[-1]):\n",
    "        DeepestZ = np.min(np.nonzero(mask2[i,:,:])[1])\n",
    "        DeepestSag.append(DeepestZ)\n",
    "    Deepestvalue = np.min(DeepestSag)\n",
    "    # possibly more than one slice with deepest brain mask, find the medium of them\n",
    "    ForamenSlice = int(np.percentile(np.where(DeepestSag==Deepestvalue),25)+ ValidSlices[0])\n",
    "    ForamenSliceReshaped = int(ForamenSlice*ConstPixelSpacing[0])\n",
    "    \n",
    "    def locateForamen(Slice):\n",
    "    \n",
    "        w = (skullcontourReshaped[ForamenSliceReshaped,:,:]!=False).astype(int)\n",
    "        sx = ndimage.sobel(w, axis=0, mode='constant')\n",
    "        sy = ndimage.sobel(w, axis=1, mode='constant')\n",
    "        sob = np.hypot(sx, sy)\n",
    "        from skimage.transform import (hough_line, hough_line_peaks,\n",
    "                                       probabilistic_hough_line)\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib import cm\n",
    "        image = w\n",
    "        edges = sob\n",
    "        lines = probabilistic_hough_line(edges, threshold=10, line_length=20,\n",
    "                                         line_gap=3)\n",
    "        cen = ndimage.measurements.center_of_mass(w)\n",
    "        #Only interested in lines lower than the center of mass\n",
    "        LowerLines = []\n",
    "        for line in lines:\n",
    "            p0,p1 = line\n",
    "            if p0[0]<cen[1] and p1[0]<cen[1]:\n",
    "                LowerLines.append(line)\n",
    "        # devide the lowerlines into two sections, detect vertical lines on upper half and horizontal lines\n",
    "        # on the lower half\n",
    "        ave_lines = np.mean(LowerLines,axis=1)\n",
    "        trans_lines = np.transpose(ave_lines)\n",
    "        sort_lines = np.sort(trans_lines[1])\n",
    "        increment = []\n",
    "        for i in range(len(sort_lines)-1):\n",
    "            inc = sort_lines[i+1]-sort_lines[i]\n",
    "            increment.append(inc)\n",
    "        Index = np.argmax(increment)\n",
    "        Critical_y = (sort_lines[Index+1]+sort_lines[Index])/2\n",
    "\n",
    "        VLines_1 = []\n",
    "        for line in LowerLines:\n",
    "            p0,p1 = line\n",
    "            if p0[1]<Critical_y and p1[1]<Critical_y:\n",
    "                VLines_1.append(line)\n",
    "        critical_x = np.mean(np.mean(VLines_1,axis=1),axis=0)[0]*1.3\n",
    "        VLines = []\n",
    "        for line in VLines_1:\n",
    "            p0,p1 = line\n",
    "            if p0[0]<critical_x and p1[0]<critical_x:\n",
    "                VLines.append(line)\n",
    "        HLines = []\n",
    "        for line in LowerLines:\n",
    "            p0,p1 = line\n",
    "            if p0[1]>Critical_y and p1[1]>Critical_y:\n",
    "                HLines.append(line)\n",
    "\n",
    "        # Locate foramen magnum in sag view\n",
    "        Vlength = []\n",
    "        for line in VLines:\n",
    "            p0,p1 = line\n",
    "            Vlength.append(np.abs(p0[0]-p1[0]))\n",
    "        VInd = np.argmax(Vlength)\n",
    "        Vpoints = VLines[VInd]\n",
    "        if Vpoints[0][0] < Vpoints[1][0]:\n",
    "            F_1 = [ForamenSliceReshaped,Vpoints[0][1],Vpoints[0][0]]\n",
    "        else:\n",
    "            F_1 = [ForamenSliceReshaped,Vpoints[1][1],Vpoints[1][0]]\n",
    "\n",
    "        Vlength = []\n",
    "        for line in VLines:\n",
    "            p0,p1 = line\n",
    "            Vlength.append(np.abs(p0[0]-p1[0]))\n",
    "        VInd = np.argmax(Vlength)\n",
    "        Vpoints = VLines[VInd]\n",
    "        if Vpoints[0][0] < Vpoints[1][0]:\n",
    "            F_1 = [ForamenSliceReshaped,Vpoints[0][1],Vpoints[0][0]]\n",
    "        else:\n",
    "            F_1 = [ForamenSliceReshaped,Vpoints[1][1],Vpoints[1][0]]\n",
    "\n",
    "        VInd_2 = np.argmin(np.transpose(VLines)[0])\n",
    "\n",
    "        if VInd_2 > len(VLines)-1:\n",
    "            F_11 = (ForamenSliceReshaped,np.transpose(VLines)[1][1][VInd_2-len(VLines)],np.transpose(VLines)[0][1][VInd_2-len(VLines)])\n",
    "        else:\n",
    "            F_11 = (ForamenSliceReshaped,np.transpose(VLines)[1][0][VInd_2],np.transpose(VLines)[0][0][VInd_2])\n",
    "\n",
    "\n",
    "        HInd = np.argmin(np.transpose(HLines)[0])\n",
    "\n",
    "        if HInd > len(HLines)-1:\n",
    "            F_2 = (ForamenSliceReshaped,np.transpose(HLines)[1][1][HInd-len(HLines)],np.transpose(HLines)[0][1][HInd-len(HLines)])\n",
    "        else:\n",
    "            F_2 = (ForamenSliceReshaped,np.transpose(HLines)[1][0][HInd],np.transpose(HLines)[0][0][HInd])\n",
    "        import math\n",
    "        if math.hypot(F_1[1]-F_11[1],F_1[2]-F_11[2]) > 25:\n",
    "        #     use the second algorithm\n",
    "            F_1 = F_11\n",
    "        else:\n",
    "            F_1 = F_1\n",
    "        return F_1, F_2\n",
    "    \n",
    "    # The probablistic hough line detection changes everytime, thus the detected foramen edges change \n",
    "    # as well. Repetitively detect the foramen points and take average reduces the random error.\n",
    "    prob_F1 = []\n",
    "    prob_F2 = []\n",
    "\n",
    "    for i in range(10):\n",
    "        F_1,F_2 = locateForamen(ForamenSliceReshaped)\n",
    "        prob_F1.append(F_1)\n",
    "        prob_F2.append(F_2)\n",
    "\n",
    "    mean_F1 = np.mean(prob_F1,axis=0,dtype=int)\n",
    "    mean_F2 = np.mean(prob_F2,axis=0,dtype=int)\n",
    "    P_1 = np.divide(F_1, np.array(ConstPixelSpacing))\n",
    "    P_2 = np.divide(F_2, np.array(ConstPixelSpacing))\n",
    "    # Need a third point to define the foramen plane.\n",
    "    # Use one slice near the ForamenSlice and locate one point F_3 in horizontal hough line, which is more accurate\n",
    "    \n",
    "    # Extract region of interest\n",
    "    img = skullcontourReshaped[ForamenSliceReshaped,:,:]\n",
    "    right_end = np.max((mean_F1[1],mean_F2[1]))\n",
    "    left_end = np.min((mean_F1[1],mean_F2[1]))\n",
    "    upper_end = np.max((mean_F1[2],mean_F2[2]))\n",
    "    ROI = img[left_end-15:right_end+15,0:upper_end+20]\n",
    "    ROI1 = bc(ROI)\n",
    "    \n",
    "    import skimage\n",
    "    labels,num = skimage.measure.label(ROI1, connectivity=1,return_num='Ture')\n",
    "    props = skimage.measure.regionprops(labels)\n",
    "    a = [p.area for p in props]\n",
    "    b = [p.centroid for p in props]\n",
    "    fill = np.zeros(ROI.shape)\n",
    "\n",
    "    def fillup(ind):\n",
    "        coords = props[ind].coords\n",
    "        for j in range(len(coords)):\n",
    "            k,l = coords[j]\n",
    "            fill[k,l] = 1\n",
    "        return fill\n",
    "    region_height = np.transpose(b)[1]\n",
    "    import heapq\n",
    "    ind = heapq.nlargest(len(region_height), xrange(len(region_height)), key=region_height.__getitem__)\n",
    "    # consider only regions with area > 10.0\n",
    "    valide_ind = []\n",
    "    for i in range(len(ind)):\n",
    "        if props[ind[i]].area > 15.0:\n",
    "            valide_ind.append(i)\n",
    "    fill = fillup(ind[valide_ind[0]])\n",
    "    # one for upper half and one for lower half edge\n",
    "    if np.multiply(props[ind[valide_ind[0]]].centroid[0] < ROI.shape[0]/2, \n",
    "                   props[ind[valide_ind[1]]].centroid[0] < ROI.shape[0]/2) == False:\n",
    "        fill = fillup(ind[valide_ind[0]])\n",
    "        fill = fillup(ind[valide_ind[1]])\n",
    "    elif np.multiply(props[ind[valide_ind[0]]].centroid[0] < ROI.shape[0]/2, \n",
    "                        props[ind[valide_ind[2]]].centroid[0] < ROI.shape[0]/2) == False:\n",
    "        fill = fillup(ind[valide_ind[0]])\n",
    "        fill = fillup(ind[valide_ind[2]])\n",
    "\n",
    "    else:\n",
    "        print('Unable to identify foramen points within ROI')\n",
    "        \n",
    "    # rewrite the img of critical slice with the cleared \n",
    "    img[left_end-15:right_end+15,0:upper_end+20] = fill\n",
    "    optimized_F1 = []\n",
    "    optimized_F2 = []\n",
    "\n",
    "    for i in range(10):\n",
    "        F_1,F_2 = locateForamen(img)\n",
    "        optimized_F1.append(F_1)\n",
    "        optimized_F2.append(F_2)\n",
    "    mean_optimized_F1 = np.mean(optimized_F1,axis=0,dtype=int)\n",
    "    mean_optimized_F2 = np.mean(optimized_F2,axis=0,dtype=int)\n",
    "    optimized_P1 = np.divide(mean_optimized_F1, np.array(ConstPixelSpacing))\n",
    "    optimized_P2 = np.divide(mean_optimized_F2, np.array(ConstPixelSpacing))\n",
    "    # Need a third point to define the foramen plane.\n",
    "    # Use one slice near the ForamenSlice and locate one point F_3 in horizontal hough line, which is more accurate\n",
    "    \n",
    "    [x1,y1,z1] = optimized_P1\n",
    "    [x2,y2,z2] = optimized_P2\n",
    "    [x3,y3,z3] = [ForamenSlice-2,optimized_P2[1],optimized_P2[2]]\n",
    "\n",
    "    vector1 = [x2 - x1, y2 - y1, z2 - z1]\n",
    "    vector2 = [x3 - x1, y3 - y1, z3 - z1]\n",
    "\n",
    "    cross_product = [vector1[1] * vector2[2] - vector1[2] * vector2[1], -1 * (vector1[0] * vector2[2] - vector1[2] * vector2[0]), vector1[0] * vector2[1] - vector1[1] * vector2[0]]\n",
    "\n",
    "    a = cross_product[0]\n",
    "    b = cross_product[1]\n",
    "    c = cross_product[2]\n",
    "    # adjust the plane by a factor of 5c in z axis to avoid cutting of positive brain volumes\n",
    "    d = cross_product[0] * x1 + cross_product[1] * y1 + cross_product[2] * z1 - 3*c\n",
    "    \n",
    "    crossShape = skull_contour[i,:,:].shape\n",
    "    mask = np.zeros(skull_contour.shape)\n",
    "    for i in range(skull_contour.shape[0]):\n",
    "        mask1 = np.fromfunction(lambda z,y: y > (d-a*i-b*z)/c-2, crossShape)\n",
    "        mask2 = np.fromfunction(lambda z,y: y < (d-a*i-b*z)/c+2, crossShape)\n",
    "        maski = np.multiply(mask1, mask2)\n",
    "        mask[i,:,:] = maski\n",
    "        \n",
    "    def saveMask(array, path, name):\n",
    "        mask = array.astype(np.float64)\n",
    "    #     mask = np.swapaxes(mask, 0, 1)\n",
    "        img = nib.Nifti1Image(mask, affine)\n",
    "        savePath = os.path.join(os.path.split(path)[0], '{}.nii.gz'.format(name))\n",
    "        nib.save(img, savePath)\n",
    "        \n",
    "    saveMask(mask,path,'opt_foramen_plane')\n",
    "    ForamenInfo.append((os.path.split(os.path.dirname(path))[1],(a,b,c,d),'slicenumber',ForamenSlice))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('opt_Foramenplanes-params.npy', np.array(ForamenInfo,dtype=object))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
